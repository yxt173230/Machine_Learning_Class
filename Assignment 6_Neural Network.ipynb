{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duck7\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (10,11,12,15,16,17,21,22,23,24,25,26,27,28,29,33,34,35,36,39,40,41,42,43,46,48,49,50,51,652,653,662,663,664,665,666,667,668,669,670,672,673,679,680,681,683,684,685,690,691,693,694,695) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>mdate</th>\n",
       "      <th>redcode</th>\n",
       "      <th>tier</th>\n",
       "      <th>ticker</th>\n",
       "      <th>shortname</th>\n",
       "      <th>docclause</th>\n",
       "      <th>spread5y</th>\n",
       "      <th>impliedrating</th>\n",
       "      <th>...</th>\n",
       "      <th>priusa</th>\n",
       "      <th>sic</th>\n",
       "      <th>spcindcd</th>\n",
       "      <th>spcseccd</th>\n",
       "      <th>spcsrc</th>\n",
       "      <th>state</th>\n",
       "      <th>stko</th>\n",
       "      <th>weburl</th>\n",
       "      <th>dldte</th>\n",
       "      <th>ipodate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1240</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>0B4414</td>\n",
       "      <td>SNRFOR</td>\n",
       "      <td>ABS</td>\n",
       "      <td>Albertsons Inc</td>\n",
       "      <td>MR</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>BBB</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>B+</td>\n",
       "      <td>ID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/02/2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1240</td>\n",
       "      <td>2002-02-28</td>\n",
       "      <td>0B4414</td>\n",
       "      <td>SNRFOR</td>\n",
       "      <td>ABS</td>\n",
       "      <td>Albertsons Inc</td>\n",
       "      <td>MR</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>BBB</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>B+</td>\n",
       "      <td>ID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/02/2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1240</td>\n",
       "      <td>2002-03-31</td>\n",
       "      <td>0B4414</td>\n",
       "      <td>SNRFOR</td>\n",
       "      <td>ABS</td>\n",
       "      <td>Albertsons Inc</td>\n",
       "      <td>MR</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>BBB</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>B+</td>\n",
       "      <td>ID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/02/2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1240</td>\n",
       "      <td>2002-04-30</td>\n",
       "      <td>0B4414</td>\n",
       "      <td>SNRFOR</td>\n",
       "      <td>ABS</td>\n",
       "      <td>Albertsons Inc</td>\n",
       "      <td>MR</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>BBB</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>B+</td>\n",
       "      <td>ID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/02/2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1240</td>\n",
       "      <td>2002-05-31</td>\n",
       "      <td>0B4414</td>\n",
       "      <td>SNRFOR</td>\n",
       "      <td>ABS</td>\n",
       "      <td>Albertsons Inc</td>\n",
       "      <td>MR</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>BBB</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>B+</td>\n",
       "      <td>ID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/02/2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 696 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gvkey       mdate redcode    tier ticker       shortname  \\\n",
       "0           0   1240  2002-01-31  0B4414  SNRFOR    ABS  Albertsons Inc   \n",
       "1           1   1240  2002-02-28  0B4414  SNRFOR    ABS  Albertsons Inc   \n",
       "2           2   1240  2002-03-31  0B4414  SNRFOR    ABS  Albertsons Inc   \n",
       "3           3   1240  2002-04-30  0B4414  SNRFOR    ABS  Albertsons Inc   \n",
       "4           4   1240  2002-05-31  0B4414  SNRFOR    ABS  Albertsons Inc   \n",
       "\n",
       "  docclause  spread5y impliedrating   ...    priusa     sic spcindcd  \\\n",
       "0        MR  0.005400           BBB   ...       1.0  5411.0    440.0   \n",
       "1        MR  0.005583           BBB   ...       1.0  5411.0    440.0   \n",
       "2        MR  0.005188           BBB   ...       1.0  5411.0    440.0   \n",
       "3        MR  0.005355           BBB   ...       1.0  5411.0    440.0   \n",
       "4        MR  0.005242           BBB   ...       1.0  5411.0    440.0   \n",
       "\n",
       "   spcseccd  spcsrc state stko weburl       dldte  ipodate  \n",
       "0     978.0      B+    ID  0.0    NaN  06/02/2006      NaN  \n",
       "1     978.0      B+    ID  0.0    NaN  06/02/2006      NaN  \n",
       "2     978.0      B+    ID  0.0    NaN  06/02/2006      NaN  \n",
       "3     978.0      B+    ID  0.0    NaN  06/02/2006      NaN  \n",
       "4     978.0      B+    ID  0.0    NaN  06/02/2006      NaN  \n",
       "\n",
       "[5 rows x 696 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### read merged csv file (see detail for merging in Assignmnet 4,5)\n",
    "\n",
    "mydata = pd.read_csv('cds_combined_with_CRSPdata.csv')\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with median and then 0\n",
    "mydata = mydata.fillna(mydata.median())\n",
    "mydata = mydata.fillna(0)\n",
    "                       \n",
    "# Keep only numerical variables\n",
    "mydata = mydata._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = mydata.drop(['Unnamed: 0','fqtr','fyearq','fyrc','fyr','ggroup','gind','gsubind','gsector','cik'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "response = \"spread5y\"\n",
    "Y = mydata[response].values\n",
    "X = mydata.drop(response,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest \n",
    "forest_fit = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136768, 40)\n",
      "(34193, 40)\n"
     ]
    }
   ],
   "source": [
    "# Find and keep the first 40 features with highest feature importance \n",
    "new_X_train = X_train[:,rf.feature_importances_.argsort()[::-1][:40]]\n",
    "new_X_test = X_test[:,rf.feature_importances_.argsort()[::-1][:40]]\n",
    "\n",
    "print(new_X_train.shape)\n",
    "print(new_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first step: create a Sequential object, as a sequence of layers. \n",
    "# B/C NN is a sequence of layers.\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(40,kernel_initializer = 'normal', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 32, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'mean_absolute_percentage_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "136768/136768 [==============================] - 22s 159us/step - loss: 114.1067\n",
      "Epoch 2/100\n",
      "136768/136768 [==============================] - 21s 156us/step - loss: 63.3682\n",
      "Epoch 3/100\n",
      "136768/136768 [==============================] - 21s 156us/step - loss: 61.9524\n",
      "Epoch 4/100\n",
      "136768/136768 [==============================] - 20s 149us/step - loss: 61.3221\n",
      "Epoch 5/100\n",
      "136768/136768 [==============================] - 21s 151us/step - loss: 60.9472\n",
      "Epoch 6/100\n",
      "136768/136768 [==============================] - 22s 163us/step - loss: 61.1034\n",
      "Epoch 7/100\n",
      "136768/136768 [==============================] - 22s 160us/step - loss: 61.6888\n",
      "Epoch 8/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 60.3162\n",
      "Epoch 9/100\n",
      "136768/136768 [==============================] - 22s 159us/step - loss: 59.8802\n",
      "Epoch 10/100\n",
      "136768/136768 [==============================] - 22s 158us/step - loss: 59.5709\n",
      "Epoch 11/100\n",
      "136768/136768 [==============================] - 21s 156us/step - loss: 59.5658\n",
      "Epoch 12/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 59.0508\n",
      "Epoch 13/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 59.0536\n",
      "Epoch 14/100\n",
      "136768/136768 [==============================] - 20s 149us/step - loss: 59.0747\n",
      "Epoch 15/100\n",
      "136768/136768 [==============================] - 20s 145us/step - loss: 58.8128\n",
      "Epoch 16/100\n",
      "136768/136768 [==============================] - 19s 142us/step - loss: 58.5833\n",
      "Epoch 17/100\n",
      "136768/136768 [==============================] - 19s 142us/step - loss: 58.6767\n",
      "Epoch 18/100\n",
      "136768/136768 [==============================] - 20s 146us/step - loss: 58.4014\n",
      "Epoch 19/100\n",
      "136768/136768 [==============================] - 20s 146us/step - loss: 58.5898\n",
      "Epoch 20/100\n",
      "136768/136768 [==============================] - 20s 145us/step - loss: 58.7402\n",
      "Epoch 21/100\n",
      "136768/136768 [==============================] - 22s 162us/step - loss: 58.4332\n",
      "Epoch 22/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 58.6667\n",
      "Epoch 23/100\n",
      "136768/136768 [==============================] - 22s 159us/step - loss: 58.3197\n",
      "Epoch 24/100\n",
      "136768/136768 [==============================] - 20s 149us/step - loss: 58.0743\n",
      "Epoch 25/100\n",
      "136768/136768 [==============================] - 21s 155us/step - loss: 58.2814\n",
      "Epoch 26/100\n",
      "136768/136768 [==============================] - 20s 146us/step - loss: 58.0955\n",
      "Epoch 27/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 58.0387\n",
      "Epoch 28/100\n",
      "136768/136768 [==============================] - 22s 162us/step - loss: 58.2026\n",
      "Epoch 29/100\n",
      "136768/136768 [==============================] - 22s 159us/step - loss: 58.0452\n",
      "Epoch 30/100\n",
      "136768/136768 [==============================] - 22s 164us/step - loss: 58.4388\n",
      "Epoch 31/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 58.1820\n",
      "Epoch 32/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 58.0006\n",
      "Epoch 33/100\n",
      "136768/136768 [==============================] - 23s 168us/step - loss: 58.1525\n",
      "Epoch 34/100\n",
      "136768/136768 [==============================] - 23s 168us/step - loss: 57.7011\n",
      "Epoch 35/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 57.8922\n",
      "Epoch 36/100\n",
      "136768/136768 [==============================] - 23s 171us/step - loss: 57.6136\n",
      "Epoch 37/100\n",
      "136768/136768 [==============================] - 23s 171us/step - loss: 57.8338\n",
      "Epoch 38/100\n",
      "136768/136768 [==============================] - 23s 171us/step - loss: 57.7521\n",
      "Epoch 39/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 57.7954\n",
      "Epoch 40/100\n",
      "136768/136768 [==============================] - 23s 169us/step - loss: 57.6521\n",
      "Epoch 41/100\n",
      "136768/136768 [==============================] - 24s 174us/step - loss: 57.7687\n",
      "Epoch 42/100\n",
      "136768/136768 [==============================] - 24s 172us/step - loss: 57.6925\n",
      "Epoch 43/100\n",
      "136768/136768 [==============================] - 24s 175us/step - loss: 57.4462\n",
      "Epoch 44/100\n",
      "136768/136768 [==============================] - 22s 161us/step - loss: 57.5815\n",
      "Epoch 45/100\n",
      "136768/136768 [==============================] - 22s 160us/step - loss: 57.5359\n",
      "Epoch 46/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 57.6405\n",
      "Epoch 47/100\n",
      "136768/136768 [==============================] - 22s 162us/step - loss: 57.9282\n",
      "Epoch 48/100\n",
      "136768/136768 [==============================] - 23s 168us/step - loss: 57.4822\n",
      "Epoch 49/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 57.3951\n",
      "Epoch 50/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 57.4691\n",
      "Epoch 51/100\n",
      "136768/136768 [==============================] - 24s 172us/step - loss: 57.5120\n",
      "Epoch 52/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 57.3197\n",
      "Epoch 53/100\n",
      "136768/136768 [==============================] - 23s 171us/step - loss: 57.2160\n",
      "Epoch 54/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 57.2562\n",
      "Epoch 55/100\n",
      "136768/136768 [==============================] - 22s 164us/step - loss: 57.1525\n",
      "Epoch 56/100\n",
      "136768/136768 [==============================] - 22s 162us/step - loss: 57.1178\n",
      "Epoch 57/100\n",
      "136768/136768 [==============================] - 22s 163us/step - loss: 57.4272\n",
      "Epoch 58/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 57.3254\n",
      "Epoch 59/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 56.9885\n",
      "Epoch 60/100\n",
      "136768/136768 [==============================] - 23s 168us/step - loss: 57.2736\n",
      "Epoch 61/100\n",
      "136768/136768 [==============================] - 22s 164us/step - loss: 57.2211\n",
      "Epoch 62/100\n",
      "136768/136768 [==============================] - 22s 163us/step - loss: 57.5562\n",
      "Epoch 63/100\n",
      "136768/136768 [==============================] - 22s 162us/step - loss: 57.0098\n",
      "Epoch 64/100\n",
      "136768/136768 [==============================] - 22s 163us/step - loss: 57.0922\n",
      "Epoch 65/100\n",
      "136768/136768 [==============================] - 22s 164us/step - loss: 57.1837\n",
      "Epoch 66/100\n",
      "136768/136768 [==============================] - 23s 165us/step - loss: 57.0744\n",
      "Epoch 67/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 57.1221\n",
      "Epoch 68/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 57.2641\n",
      "Epoch 69/100\n",
      "136768/136768 [==============================] - 23s 168us/step - loss: 57.1052\n",
      "Epoch 70/100\n",
      "136768/136768 [==============================] - 23s 168us/step - loss: 56.9577\n",
      "Epoch 71/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 57.3385\n",
      "Epoch 72/100\n",
      "136768/136768 [==============================] - 22s 162us/step - loss: 57.0867\n",
      "Epoch 73/100\n",
      "136768/136768 [==============================] - 22s 163us/step - loss: 56.9331\n",
      "Epoch 74/100\n",
      "136768/136768 [==============================] - 22s 165us/step - loss: 57.0358\n",
      "Epoch 75/100\n",
      "136768/136768 [==============================] - 23s 167us/step - loss: 57.3362\n",
      "Epoch 76/100\n",
      "136768/136768 [==============================] - 23s 166us/step - loss: 57.1540\n",
      "Epoch 77/100\n",
      "136768/136768 [==============================] - 23s 170us/step - loss: 56.9662\n",
      "Epoch 78/100\n",
      "136768/136768 [==============================] - 23s 169us/step - loss: 57.1213\n",
      "Epoch 79/100\n",
      "136768/136768 [==============================] - 23s 169us/step - loss: 57.3888\n",
      "Epoch 80/100\n",
      "136768/136768 [==============================] - 25s 182us/step - loss: 57.1288\n",
      "Epoch 81/100\n",
      "136768/136768 [==============================] - 28s 203us/step - loss: 57.0536\n",
      "Epoch 82/100\n",
      "136768/136768 [==============================] - 27s 195us/step - loss: 56.8863\n",
      "Epoch 83/100\n",
      "136768/136768 [==============================] - 30s 217us/step - loss: 56.9801\n",
      "Epoch 84/100\n",
      "136768/136768 [==============================] - 30s 217us/step - loss: 57.0025\n",
      "Epoch 85/100\n",
      "136768/136768 [==============================] - 23s 171us/step - loss: 56.9207\n",
      "Epoch 86/100\n",
      "136768/136768 [==============================] - 24s 173us/step - loss: 57.0900\n",
      "Epoch 87/100\n",
      "136768/136768 [==============================] - 24s 177us/step - loss: 57.0505\n",
      "Epoch 88/100\n",
      "136768/136768 [==============================] - 22s 164us/step - loss: 56.9258\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136768/136768 [==============================] - 20s 148us/step - loss: 56.8485\n",
      "Epoch 90/100\n",
      "136768/136768 [==============================] - 20s 147us/step - loss: 57.1007\n",
      "Epoch 91/100\n",
      "136768/136768 [==============================] - 20s 147us/step - loss: 56.9808\n",
      "Epoch 92/100\n",
      "136768/136768 [==============================] - 21s 153us/step - loss: 56.6892\n",
      "Epoch 93/100\n",
      "136768/136768 [==============================] - 21s 150us/step - loss: 57.0075\n",
      "Epoch 94/100\n",
      "136768/136768 [==============================] - 21s 151us/step - loss: 56.8937\n",
      "Epoch 95/100\n",
      "136768/136768 [==============================] - 21s 154us/step - loss: 56.8791\n",
      "Epoch 96/100\n",
      "136768/136768 [==============================] - 20s 149us/step - loss: 56.5664\n",
      "Epoch 97/100\n",
      "136768/136768 [==============================] - 21s 156us/step - loss: 57.0859\n",
      "Epoch 98/100\n",
      "136768/136768 [==============================] - 21s 157us/step - loss: 56.7184\n",
      "Epoch 99/100\n",
      "136768/136768 [==============================] - 21s 153us/step - loss: 56.8983\n",
      "Epoch 100/100\n",
      "136768/136768 [==============================] - 20s 150us/step - loss: 57.2917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b5a81d8978>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(new_X_train, y_train, batch_size = 5, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.82093178690397"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "MAPE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
